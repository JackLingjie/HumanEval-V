{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_at_K(passed_results_by_qid, k=[1, 10]):\n",
    "    # Calculate pass@k.\n",
    "    total, correct = [], []\n",
    "    for passed in passed_results_by_qid.values():\n",
    "        total.append(len(passed))\n",
    "        correct.append(sum(passed))\n",
    "\n",
    "    total = np.array(total)\n",
    "    correct = np.array(correct)\n",
    "\n",
    "    ks = k\n",
    "    return {f\"pass@{k}\": round(float(_estimate_pass_at_k(total, correct, k).mean())*100, 1)\n",
    "            for k in ks if (total >= k).all()}\n",
    "            \n",
    "def compute_score(execution_results):\n",
    "    passed_results_by_qid = defaultdict(list)\n",
    "    pylint_failed_count = 0\n",
    "    sample_num = 1\n",
    "    for item in execution_results:\n",
    "        qid = item['qid']\n",
    "        sample_num = len(item['predictions'])\n",
    "        results = item['results']\n",
    "        for result in results:\n",
    "            passed_results_by_qid[qid].append(result['passed'])\n",
    "            pylint_failed_count += 1 if result['result'].startswith(\"pylint fail\") else 0\n",
    "            \n",
    "    k = [1] if sample_num == 1 else [10]\n",
    "    scores = pass_at_K(passed_results_by_qid, k)\n",
    "    passed_qids = sorted([k for k, v in passed_results_by_qid.items() if any(v)])\n",
    "    print(f\"Pass@{k[0]}: {scores}\")\n",
    "    print(f\"Parsing Success Rate: {round(100*(1 - pylint_failed_count / (sample_num*len(execution_results))), 1)}%\")\n",
    "    print(f\"Passed QIDs: {passed_qids}\")\n",
    "\n",
    "def load_json(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        return []\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def main(prediction_file, score_only=False):\n",
    "\n",
    "    execution_results = load_json(prediction_file.replace(\".json\", \"_executed.json\"))\n",
    "    compute_score(execution_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import json  \n",
    "from collections import defaultdict  \n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import itertools\n",
    "\n",
    "\n",
    "def _estimator(n: int, c: int, k: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculates comb(n - c, k) / comb(n, k).\n",
    "    \"\"\"\n",
    "    if n - c < k:\n",
    "        return 0\n",
    "    return np.prod(1.0 - k / np.arange(n - c + 1, n + 1))\n",
    "def _estimate_pass_at_k(num_samples, num_correct, k) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Estimates pass@k of each problem and returns them in an array.\n",
    "    \"\"\"\n",
    "    if isinstance(num_samples, int):\n",
    "        num_samples_it = itertools.repeat(num_samples, len(num_correct))\n",
    "    else:\n",
    "        assert len(num_samples) == len(num_correct)\n",
    "        num_samples_it = iter(num_samples)\n",
    "\n",
    "    return np.array([1.0 - _estimator(int(n), int(c), k) for n, c in zip(num_samples_it, num_correct)])\n",
    "\n",
    "\n",
    "def pass_at_K(passed_results_by_qid, k=[1, 10]):\n",
    "    # Calculate pass@k.\n",
    "    total, correct = [], []\n",
    "    for passed in passed_results_by_qid.values():\n",
    "        total.append(len(passed))\n",
    "        correct.append(sum(passed))\n",
    "\n",
    "    total = np.array(total)\n",
    "    correct = np.array(correct)\n",
    "\n",
    "    ks = k\n",
    "    return {f\"pass@{k}\": round(float(_estimate_pass_at_k(total, correct, k).mean())*100, 1)\n",
    "            for k in ks if (total >= k).all()}\n",
    "            \n",
    "def compute_score(execution_results):  \n",
    "    passed_results_by_qid = defaultdict(list)  \n",
    "    pylint_failed_count = 0  \n",
    "    sample_num = 1  \n",
    "    for item in execution_results:  \n",
    "        qid = item['qid']  \n",
    "        sample_num = len(item['predictions'])  \n",
    "        results = item['results']  \n",
    "        for result in results:  \n",
    "            passed_results_by_qid[qid].append(result['passed'])  \n",
    "            pylint_failed_count += 1 if result['result'].startswith(\"pylint fail\") else 0  \n",
    "  \n",
    "    k = [1] if sample_num == 1 else [10]  \n",
    "    scores = pass_at_K(passed_results_by_qid, k)  \n",
    "      \n",
    "    pass_at_1 = scores.get('pass@1', None)  \n",
    "    parsing_success_rate = round(100 * (1 - pylint_failed_count / (sample_num * len(execution_results))), 1)  \n",
    "  \n",
    "    # Return only relevant scores  \n",
    "    return {  \n",
    "        \"Pass@1\": pass_at_1,  \n",
    "        \"Parsing Success Rate\": parsing_success_rate  \n",
    "    } \n",
    " \n",
    "def load_json(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        return []\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "def process_files_in_output_directory():  \n",
    "    results = {}  \n",
    "    output_dir = 'output'  \n",
    "    for file_name in os.listdir(output_dir):  \n",
    "        if file_name.endswith('_executed.json'):  \n",
    "            prediction_file = os.path.join(output_dir, file_name)  \n",
    "            execution_results = load_json(prediction_file)  \n",
    "            key = file_name.replace('_executed.json', '')  \n",
    "            results[key] = compute_score(execution_results)  \n",
    "  \n",
    "    # Save results to CSV  \n",
    "    df = pd.DataFrame.from_dict(results, orient='index')  \n",
    "    df.to_csv('results_human_v.csv')  \n",
    "process_files_in_output_directory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "design",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
